{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The goal of this notebook is to query data from the Bitcoin blockchain in order extract a few on-chain insights. To do so, you'd be using [Google's BigQuery Bitcoin Database](https://cloud.google.com/blog/topics/public-datasets/bitcoin-in-bigquery-blockchain-analytics-on-public-data).\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two ways in which you can interact with __Bitcoin's BigQuery DB__.\n",
    "\n",
    "1. __If you have a Google Cloud Platform account, or you set one up, you can interact with the database directly.__\n",
    "\n",
    "In order to be able to query data from `BigQuery`, you need to authenticate. Go to your GCP project and create a new project. Select `APIs & Services > Dashboard > Enable APIs and Services`. Click on Manage. Once enabled head to `APIs & Services > Credentials > Create credentials > Service account key > New service account`. Create a service account with a role (__owner__) that let's you query BigQuery data (e.g. BigQuery Data Admin) and download the key as JSON. Then simply define an environment variable that points to the JSON file, e.g.\n",
    "\n",
    "There is more than one simpler way of making it working by explicity mentioning Credentials and passing them to client as shown below:\n",
    "\n",
    "a)\n",
    "> `export GOOGLE_APPLICATION_CREDENTIALS=\"/your/path/to/gcp_credentials.json\"`\n",
    "\n",
    "b)\n",
    "> `os.environ['GOOGLE_APPLICATION_CREDENTIALS']=\"/your/path/to/gcp_credentials.json\"`\n",
    "\n",
    "Done! You should be able to make queries on the Bitcoin BigQuery database.\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "2. __You can also use Kaggle's public dataset BigQuery integration__.\n",
    "\n",
    "There's a nice tutorial about `SQL` and `BigQueries` in this [notebook](https://www.kaggle.com/rtatman/sql-scavenger-hunt-handbook/) by Kaggle's Grandmaster Rachael Tatman.\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the BigQuery client library for Python provides a magic command that lets you run queries with minimal code\n",
    "%load_ext google.cloud.bigquery\n",
    "\n",
    "# importing libraries\n",
    "import pandas as pd\n",
    "#import pandas_gbq\n",
    "from google.cloud import bigquery\n",
    "#import bq_helper # unfortunetly this library is only available for kaggle's kernels\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color= red> WARNING </font>: Be aware of malicious actors on the internet, DO NOT SHARE any personal information or keys on a public website like Github!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# connecting to Google datastore:\n",
    "\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS']=\"llave1.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a client\n",
    "\n",
    "client = bigquery.Client()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### BIG DISCLAIMER when running bigqueries\n",
    "\n",
    "_Don't rely on __LIMIT__: One of the things that can be confusing when working with BigQuery datasets is the difference between the data you scan and the data you actually get back especially since it's the first one that actually counts against your quota. When you do something like select a column with LIMIT = 10, you'll only get 10 results back... but you'll actually be scanning the whole column. It's not a big deal if your table has 1000 rows, but it's a much bigger deal if it has 10,000,000 rows!_\n",
    "\n",
    "__Since the monthly quota for BigQuery queries is 5 terabytes, you can easily go past your 30-day quota by running just a couple of queries!__\n",
    "\n",
    "To put this into some perspective the table [`transactions`] of the crypto_bitcoin dataset on GCP is almost 2 TB... So be very careful when running your queries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Explore a bit the dataset's summary [here](https://www.kaggle.com/bigquery/bitcoin-blockchain?select=transactions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â query\n",
    "# this size of this query is 1.42 TB\n",
    "\n",
    "# Apr 12th - Apr 15th\n",
    "# 678973 - 679422\n",
    "\n",
    "# 679250 AND 679422 -> one day Apr 14th\n",
    "\n",
    "\n",
    "query = \"\"\"\n",
    "    SELECT\n",
    "        size, \n",
    "        block_number, \n",
    "        block_timestamp, \n",
    "        input_count, \n",
    "        output_count, \n",
    "        is_coinbase, \n",
    "        fee, \n",
    "        inputs, \n",
    "        outputs\n",
    "        \n",
    "    FROM `bigquery-public-data.crypto_bitcoin.transactions`\n",
    "    WHERE block_number BETWEEN 679250 AND 679422\n",
    "    ORDER BY block_number\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# client.query() method runs the query\n",
    "\n",
    "df = client.query(query).to_dataframe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('blocks.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit",
   "language": "python",
   "name": "python37364bita5c255c08ee84ee995db25a1aa26e8dd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
